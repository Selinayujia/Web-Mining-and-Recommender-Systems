{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:199000]\n",
    "ratingsValid = allRatings[199000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "bcf70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction (CSE258 only)                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "95b960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "46c28bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred_rs, actual_rs):\n",
    "    differences = [(pred_r - actual_r)**2 for pred_r, actual_r in zip(pred_rs,actual_rs)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "6d69e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "    \n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(u, b) for u, b, r in ratingsTrain]\n",
    "    cost = MSE(predictions, labels)\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(ratingsTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for u, b, r in ratingsTrain:\n",
    "        u,i = u, b\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "754eb9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.68671980e+00, -2.38027839e-04,  1.10201785e-05, ...,\n",
       "        -3.45209992e-06, -3.45196940e-06, -1.35034005e-05]),\n",
       " 1.7384416397385736,\n",
       " {'grad': array([ 4.51853336e-07, -8.63163363e-08, -7.00026040e-09, ...,\n",
       "         -2.28477780e-09, -2.28587574e-09, -4.85978371e-09]),\n",
       "  'task': 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'funcalls': 4,\n",
       "  'nit': 2,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "lamb = 1\n",
    "\n",
    "labels = [r[2] for r in ratingsTrain]\n",
    "ratingMean = sum(labels)/len(ratingsTrain)\n",
    "\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())\n",
    "nUsers = len(users)\n",
    "nItems = len(items)\n",
    "\n",
    "alpha = ratingMean\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "a0d1e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating\n",
    "preds = []\n",
    "valid_labels  = []\n",
    "\n",
    "for u, b, r in ratingsValid:\n",
    "    valid_labels.append(r)\n",
    "    if u in userBiases and b in itemBiases:\n",
    "        preds.append(prediction(u, b))\n",
    "    else:\n",
    "        user_ratings = [user_rating[1] for user_rating in ratingsPerUser[u]]\n",
    "        if u in userBiases and b in itemBiases:\n",
    "            preds.append(prediction(u, b))\n",
    "        elif u not in userBiases and b not in itemBiases:\n",
    "            preds.append(ratingMean)\n",
    "        elif u not in userBiases:\n",
    "            preds.append(ratingMean + itemBiases[b])\n",
    "        else:\n",
    "            preds.append(ratingMean + userBiases[u])\n",
    "validMSE = MSE(preds, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "422ab930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7218158966626704\n"
     ]
    }
   ],
   "source": [
    "answers['Q9'] = validMSE\n",
    "print(validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "0a416949",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "ae54cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "lambs = [10**(i/10) for i in range(-52, -45)]\n",
    "mses = []\n",
    "for lamb in lambs:\n",
    "    scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                                 derivative, args = (labels, lamb))\n",
    "\n",
    "    preds = []\n",
    "    valid_labels  = []\n",
    "\n",
    "    for u, b, r in ratingsValid:\n",
    "        valid_labels.append(r)\n",
    "        if u in userBiases and b in itemBiases:\n",
    "            preds.append(prediction(u, b))\n",
    "        elif u not in userBiases and b not in itemBiases:\n",
    "            preds.append(ratingMean)\n",
    "        elif u not in userBiases:\n",
    "            preds.append(ratingMean + itemBiases[b])\n",
    "        else:\n",
    "            preds.append(ratingMean + userBiases[u])\n",
    "        \n",
    "    mses.append(MSE(preds, valid_labels))\n",
    "\n",
    "validMSE = min(mses)\n",
    "lamb = lambs[mses.index(validMSE)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "f1880fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9952623149688786e-05\n",
      "[1.3772273056904478, 1.3671498658419334, 1.3580069526155705, 1.3507728303799416, 1.3457975481380313, 1.3438824290652447, 1.3453388454964719]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q11'] = (lamb, validMSE)\n",
    "print(lamb), print(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "4b0b72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.30957344480193e-06, 7.943282347242822e-06, 1e-05, 1.2589254117941661e-05, 1.584893192461114e-05, 1.9952623149688786e-05, 2.5118864315095822e-05]\n"
     ]
    }
   ],
   "source": [
    "print(lambs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "b9bd53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in allRatings:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    \n",
    "labels = [r[2] for r in allRatings]\n",
    "ratingMean = sum(labels)/len(allRatings)\n",
    "\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())\n",
    "nUsers = len(users)\n",
    "nItems = len(items)\n",
    "\n",
    "alpha = ratingMean\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, lamb))\n",
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    " \n",
    "    if u in userBiases and b in itemBiases:\n",
    "        predictions.write(u + ',' + b + ',' + str(prediction(u, b)) + \"\\n\")\n",
    "    elif u not in userBiases and b not in itemBiases:\n",
    "        predictions.write(u + ',' + b + ',' + str(ratingMean) + \"\\n\")\n",
    "    elif u not in userBiases:\n",
    "        \n",
    "        predictions.write(u + ',' + b + ',' + str(ratingMean + itemBiases[b]) + \"\\n\")\n",
    "    else:\n",
    "        predictions.write(u + ',' + b + ',' + str(ratingMean + userBiases[u]) + \"\\n\")\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a recommendation based on the popularity of the book\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "ratingsTrain = allRatings[:199500]\n",
    "ratingsValid = allRatings[199500:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNegative(allRatings, valid):\n",
    "    validWithNeg = []\n",
    "    userBookList = defaultdict(set)\n",
    "    allBookList = set()\n",
    "    for u, b, r in allRatings:\n",
    "        userBookList[u].add(b)\n",
    "        allBookList.add(b)\n",
    "    \n",
    "    for u, b, r in valid:\n",
    "        validWithNeg.append((u,b,r,1)) # 1 stands for read\n",
    "        aBookUserNeverRead = random.sample(allBookList - userBookList[u], 1)[0]\n",
    "        validWithNeg.append((u, aBookUserNeverRead, 0, 0))\n",
    "    return validWithNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d53c2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "validWithNegative = sampleNegative(allRatings, ratingsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendationWThreshold(totalRead, mostPopular, t):\n",
    "    recommendation = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        recommendation.add(i)\n",
    "        if count > int(totalRead*(t/100)): break\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5ccfffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating accuracy of recommendations with different thresholds\n",
    "thresholds = [i/10 for i in range(700,720)]\n",
    "# Here threshold is defined as the percentage of the popularity book we are recommending (Q1 is 50)\n",
    "acc = []\n",
    "for threshold in thresholds:\n",
    "    recommendation = recommendationWThreshold(totalRead, mostPopular, threshold)\n",
    "    correct = 0\n",
    "    for u, b, r, read in validWithNegative:\n",
    "        if b in recommendation:\n",
    "            if read: correct +=1\n",
    "        else:\n",
    "            if not read: correct+=1\n",
    "    acc.append(correct/len(validWithNegative))\n",
    "    \n",
    "threshold, acc2 = (thresholds[acc.index(max(acc))], max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.9 0.753\n"
     ]
    }
   ],
   "source": [
    "answers['Q2'] = [threshold, acc2]\n",
    "print(threshold, acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "18cdfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    result = len(s1 & s2) / len(s1 | s2) if len(s1 | s2) != 0 else 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a5acc3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 0.736\n"
     ]
    }
   ],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    \n",
    "thresholds = [i for i in range(40,51)] \n",
    "# Here threshold is defined as the percentage of the jaccard similarity\n",
    "acc = []\n",
    "for threshold in thresholds:\n",
    "    correct = 0\n",
    "    for u, b, r, read in validWithNegative:\n",
    "        books_u_read = [book_rating[0] for book_rating in ratingsPerUser[u]]\n",
    "        users_read_b = [user_rating[0] for user_rating in ratingsPerItem[b]]\n",
    "\n",
    "        book_jaccard_scores = []\n",
    "        for book in books_u_read:\n",
    "            users_read_book = [user_rating[0] for user_rating in ratingsPerItem[book]]\n",
    "            book_jaccard_scores.append(Jaccard(set(users_read_b), set(users_read_book)))\n",
    "\n",
    "        user_jaccard_scores = []\n",
    "        for user in users_read_b:\n",
    "            books_user_read = [user_rating[0] for user_rating in ratingsPerUser[user]]\n",
    "            user_jaccard_scores.append(Jaccard(set(books_u_read), set(books_user_read)))\n",
    "\n",
    "\n",
    "        if not book_jaccard_scores and not user_jaccard_scores:\n",
    "            jaccard = 0\n",
    "        elif not user_jaccard_scores:\n",
    "            jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))*0.5\n",
    "        elif not book_jaccard_scores:\n",
    "            jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))*0.5\n",
    "        else:\n",
    "            book_jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))\n",
    "            user_jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))\n",
    "            jaccard = 0.5*book_jaccard + 0.5*user_jaccard\n",
    "\n",
    "            if jaccard >= threshold/1000: # this current book is considered as a good fit\n",
    "                if read: correct +=1\n",
    "            else:\n",
    "                if not read: correct +=1\n",
    "    acc.append(correct/len(validWithNegative))\n",
    "    \n",
    "threshold_new, acc3_5 = (thresholds[acc.index(max(acc))], max(acc))\n",
    "print(threshold_new, acc3_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "c24e812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.735\n"
     ]
    }
   ],
   "source": [
    "thresholds = [i/100 for i in range(50,65)] \n",
    "\n",
    "# Here threshold is defined as the percentage of the jaccard similarity\n",
    "acc = []\n",
    "for threshold in thresholds:\n",
    "    correct = 0\n",
    "    for u, b, r, read in validWithNegative:\n",
    "        books_u_read = [book_rating[0] for book_rating in ratingsPerUser[u]]\n",
    "        users_read_b = [user_rating[0] for user_rating in ratingsPerItem[b]]\n",
    "\n",
    "        book_jaccard_scores = []\n",
    "        for book in books_u_read:\n",
    "            users_read_book = [user_rating[0] for user_rating in ratingsPerItem[book]]\n",
    "            book_jaccard_scores.append(Jaccard(set(users_read_b), set(users_read_book)))\n",
    "\n",
    "        user_jaccard_scores = []\n",
    "        for user in users_read_b:\n",
    "            books_user_read = [user_rating[0] for user_rating in ratingsPerUser[user]]\n",
    "            user_jaccard_scores.append(Jaccard(set(books_u_read), set(books_user_read)))\n",
    "\n",
    "\n",
    "        if not book_jaccard_scores and not user_jaccard_scores:\n",
    "            jaccard = 0\n",
    "        elif not user_jaccard_scores:\n",
    "            jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))*threshold\n",
    "        elif not book_jaccard_scores:\n",
    "            jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))*(1-threshold)\n",
    "        else:\n",
    "            book_jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))\n",
    "            user_jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))\n",
    "            jaccard = threshold*book_jaccard + (1-threshold)*user_jaccard\n",
    "\n",
    "            if jaccard >= 48/1000: # this current book is considered as a good fit\n",
    "                if read: correct +=1\n",
    "            else:\n",
    "                if not read: correct +=1\n",
    "    acc.append(correct/len(validWithNegative))\n",
    "    \n",
    "threshold_new_1, acc3_25 = (thresholds[acc.index(max(acc))], max(acc))\n",
    "print(threshold_new_1, acc3_25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "0eb327f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n"
     ]
    }
   ],
   "source": [
    "# Evaluating accuracy of recommendations with the BEST jaccard threshold and popularity threshold\n",
    "bestJaccardThreshold = 80\n",
    "bestPopularityThreshold = 71.8 #71.8 #71.2\n",
    "bestTheta = 0.63 #0.62 #0.55\n",
    "\n",
    "recommendation = recommendationWThreshold(totalRead, mostPopular,bestPopularityThreshold)\n",
    "# Here threshold is defined as the percentage of the jaccard similarity\n",
    "correct = 0\n",
    "for u, b, r, read in validWithNegative:\n",
    "    books_u_read = [book_rating[0] for book_rating in ratingsPerUser[u]]\n",
    "    users_read_b = [user_rating[0] for user_rating in ratingsPerItem[b]]\n",
    "    \n",
    "    book_jaccard_scores = []\n",
    "    for book in books_u_read:\n",
    "        users_read_book = [user_rating[0] for user_rating in ratingsPerItem[book]]\n",
    "        book_jaccard_scores.append(Jaccard(set(users_read_b), set(users_read_book)))\n",
    "        \n",
    "    user_jaccard_scores = []\n",
    "    for user in users_read_b:\n",
    "        books_user_read = [user_rating[0] for user_rating in ratingsPerUser[user]]\n",
    "        user_jaccard_scores.append(Jaccard(set(books_u_read), set(books_user_read)))\n",
    "    \n",
    "            \n",
    "    if not book_jaccard_scores and not user_jaccard_scores:\n",
    "        jaccard = 0\n",
    "    elif not user_jaccard_scores:\n",
    "        jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))*bestTheta\n",
    "    elif not book_jaccard_scores:\n",
    "        jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))*(1-bestTheta)\n",
    "    else:\n",
    "        book_jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))\n",
    "        user_jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))\n",
    "        jaccard = (bestTheta)*book_jaccard + (1-bestTheta)*user_jaccard\n",
    "\n",
    "    if b in recommendation:\n",
    "        if read: correct +=1\n",
    "    else:\n",
    "        if jaccard >= bestJaccardThreshold/1000:\n",
    "            if read: correct +=1\n",
    "        else:\n",
    "            if not read: correct += 1\n",
    "acc4 = correct/len(validWithNegative)\n",
    "    \n",
    "print(acc4) # 0.7562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "14f911e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in allRatings:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestJaccardThreshold = 80#80\n",
    "bestPopularityThreshold = 71.8 # 71.2\n",
    "bestTheta = 0.63 #0.6\n",
    "recommendation = recommendationWThreshold(totalRead, mostPopular,bestPopularityThreshold)\n",
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    \n",
    "    books_u_read = [book_rating[0] for book_rating in ratingsPerUser[u]]\n",
    "    users_read_b = [user_rating[0] for user_rating in ratingsPerItem[b]]\n",
    "    \n",
    "    book_jaccard_scores = []\n",
    "    for book in books_u_read:\n",
    "        users_read_book = [user_rating[0] for user_rating in ratingsPerItem[book]]\n",
    "        book_jaccard_scores.append(Jaccard(set(users_read_b), set(users_read_book)))\n",
    "        \n",
    "    user_jaccard_scores = []\n",
    "    for user in users_read_b:\n",
    "        books_user_read = [user_rating[0] for user_rating in ratingsPerUser[user]]\n",
    "        user_jaccard_scores.append(Jaccard(set(books_u_read), set(books_user_read)))\n",
    "    \n",
    "            \n",
    "    if not book_jaccard_scores and not user_jaccard_scores:\n",
    "        jaccard = 0\n",
    "    elif not user_jaccard_scores:\n",
    "        jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))*bestTheta\n",
    "    elif not book_jaccard_scores:\n",
    "        jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))*(1-bestTheta)\n",
    "    else:\n",
    "        book_jaccard = max(max(book_jaccard_scores), sum(book_jaccard_scores))\n",
    "        user_jaccard = max(max(user_jaccard_scores), sum(user_jaccard_scores))\n",
    "        jaccard = (bestTheta)*book_jaccard + (1-bestTheta)*user_jaccard\n",
    "        \n",
    "    if b in recommendation:\n",
    "        predictions.write(u + ',' + b + \",1\\n\")\n",
    "    else:\n",
    "        if jaccard >= bestJaccardThreshold/1000:\n",
    "            predictions.write(u + ',' + b + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(u + ',' + b + \",0\\n\")\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd852a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
