{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "dbcb905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "94e03340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "8bbbc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "85c00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"5year.arff\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "6fad4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse the data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7691e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "03249990",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {} # Your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "a31a5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    TP = sum(numpy.logical_and(predictions, y))\n",
    "    FP = sum(numpy.logical_and(predictions, numpy.logical_not(y)))\n",
    "    TN = sum(numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(y)))\n",
    "    FN = sum(numpy.logical_and(numpy.logical_not(predictions), y))\n",
    "\n",
    "    return (TP + TN) / (TP + FP + TN + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "83974166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BER(predictions, y):\n",
    "    TP = sum(numpy.logical_and(predictions, y))\n",
    "    FP = sum(numpy.logical_and(predictions, numpy.logical_not(y)))\n",
    "    TN = sum(numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(y)))\n",
    "    FN = sum(numpy.logical_and(numpy.logical_not(predictions), y))\n",
    "\n",
    "    return 1 - 0.5*(TP / (TP + FN) + TN / (TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "5e78a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "f59633dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "acc1 = accuracy(pred, y)\n",
    "ber1 = BER(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "033a6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [acc1, ber1] # Accuracy and balanced error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "e75988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "30482ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "bc8f8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "acc2 = accuracy(pred, y)\n",
    "ber2 = BER(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "de8d6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [acc2, ber2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "8a90cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e1fa1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "55d4beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "d19c0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "18d5fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "6d66f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 758, 758, 1515, 758, 758)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain), len(Xvalid), len(Xtest), len(ytrain), len(yvalid), len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "ff366999",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(C=1, class_weight='balanced')\n",
    "mod.fit(Xtrain,ytrain)\n",
    "\n",
    "predTrain = mod.predict(Xtrain)\n",
    "predValid = mod.predict(Xvalid)\n",
    "predTest = mod.predict(Xtest)\n",
    "\n",
    "berTrain = BER(predTrain, ytrain)\n",
    "berValid = BER(predValid, yvalid)\n",
    "berTest = BER(predTest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "0bb40dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [berTrain, berValid, berTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "9e0ece86",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "81d44cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "5ff0daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = [10**c for c in range(-4, 5)]\n",
    "berList = []\n",
    "for c in c_s:\n",
    "    mod = linear_model.LogisticRegression(C=c, class_weight='balanced')\n",
    "\n",
    "    mod.fit(Xvalid,yvalid)\n",
    "    predValid = mod.predict(Xvalid)\n",
    "    berValid = BER(predValid, yvalid)\n",
    "    berList.append(berValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "3c96b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = berList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f55f3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "8b455b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "2a80d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ber_pair = zip(c_s, berList) \n",
    "bestC, ber5 = sorted(c_ber_pair, key=lambda x: x[-1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "62bdaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = [bestC, ber5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b8cafe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "fcbc2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "ace19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(\"young_adult_10000.json.gz\")\n",
    "dataset = []\n",
    "for l in f:\n",
    "    dataset.append(eval(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "06598b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = dataset[:9000]\n",
    "dataTest = dataset[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "4209458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures you might want\n",
    "\n",
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "ratings = []\n",
    "for d in dataTrain:\n",
    "    user = d[\"user_id\"]\n",
    "    item = d[\"book_id\"]\n",
    "    rating = d[\"rating\"]\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)\n",
    "    ratingDict[f'{user}_{item}'] = rating\n",
    "    ratings.append(rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "03c90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    result = len(s1 & s2) / len(s1 | s2) if len(s1 | s2) != 0 else 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "25bfacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar(i, N):\n",
    "    similarities = [(Jaccard(usersPerItem[i], usersPerItem[item]), item) for item in usersPerItem if item != i]\n",
    "    return sorted(similarities, reverse=True, key=lambda x : x[0])[:N]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "2652a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = mostSimilar('2767052', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "35457af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.4125, '6148028'), (0.3411764705882353, '7260188'), (0.1590909090909091, '256683'), (0.1375, '1162543'), (0.11494252873563218, '11735983'), (0.10989010989010989, '13335037'), (0.10810810810810811, '28187'), (0.10666666666666667, '428263'), (0.09876543209876543, '49041'), (0.09782608695652174, '41865')]\n"
     ]
    }
   ],
   "source": [
    "assert len(answers['Q6']) == 10\n",
    "assertFloatList([x[0] for x in answers['Q6']], 10)\n",
    "print(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "69798ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "2ab5cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "\n",
    "for u in itemsPerUser:\n",
    "    rs = [ratingDict[f'{u}_{i}'] for i in itemsPerUser[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[f'{u}_{i}'] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)\n",
    "    \n",
    "ratingMean = sum(ratings)/len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "b8a27183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(u, i):\n",
    "    differences = []\n",
    "    similarities = []                \n",
    "    for j in itemsPerUser[u]:\n",
    "        if j != i:\n",
    "            r_u_j = ratingDict[f'{u}_{j}']\n",
    "            average_j_rating = itemAverages[j] # rj bar\n",
    "            difference = r_u_j - average_j_rating # r_u_j - rj bar\n",
    "            similarity = Jaccard(usersPerItem[i], usersPerItem[j])\n",
    "            differences.append(difference)\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    weighted = zip(differences, similarities)\n",
    "    result = itemAverages[i] + (sum([d*s for d, s in weighted]) / sum(similarities)) if sum(similarities) != 0 else ratingMean\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "e386e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rs = []\n",
    "actual_rs = []\n",
    "for d in dataTest:\n",
    "    pred_rs.append(predict_rating(d['user_id'], d['book_id']))\n",
    "    actual_rs.append(d['rating'])\n",
    "    \n",
    "    \n",
    "def MSE(pred_rs, actual_rs):\n",
    "    differences = [(pred_r - actual_r)**2 for pred_r, actual_r in zip(pred_rs,actual_rs)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "mse7= MSE(pred_rs, actual_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "0e3f9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = mse7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "f7d294f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2469091498159586\n"
     ]
    }
   ],
   "source": [
    "assertFloat(answers['Q7'])\n",
    "print(mse7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "088d0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "781abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_2(u, i):\n",
    "    differences = []\n",
    "    similarities = []                \n",
    "    for v in usersPerItem[i]:\n",
    "        if v != u:\n",
    "            r_v_i = ratingDict[f'{v}_{i}']\n",
    "            average_v_rating = userAverages[v] # rv bar\n",
    "            difference = r_v_i - average_v_rating # r_v_i - rv bar\n",
    "            similarity = Jaccard(itemsPerUser[u], itemsPerUser[v])\n",
    "            differences.append(difference)\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    weighted = zip(differences, similarities)\n",
    "    result = itemAverages[i] + (sum([d*s for d, s in weighted]) / sum(similarities)) if sum(similarities) != 0 else ratingMean\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "04cefad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rs = []\n",
    "actual_rs = []\n",
    "for d in dataTest:\n",
    "    pred_rs.append(predict_rating_2(d['user_id'], d['book_id']))\n",
    "    actual_rs.append(d['rating'])\n",
    "    \n",
    "    \n",
    "def MSE(pred_rs, actual_rs):\n",
    "    differences = [(pred_r - actual_r)**2 for pred_r, actual_r in zip(pred_rs,actual_rs)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "mse8= MSE(pred_rs, actual_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "2461deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = mse8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "def088ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "f534c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw2.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
